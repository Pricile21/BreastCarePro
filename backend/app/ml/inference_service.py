#!/usr/bin/env python3
"""
Service d'inference pour le mod√®le MedSigLIP entra√Æn√©
Utilise le mod√®le best_medsiglip_model.pth pour la pr√©diction
"""

import torch
import torch.nn as nn
import numpy as np
import cv2
from PIL import Image
import os
from pathlib import Path
from transformers import AutoProcessor, AutoModel
import warnings
warnings.filterwarnings("ignore")

class MedSigLIPInferenceService:
    """
    Service d'inference pour MedSigLIP
    """
    
    def __init__(self, model_path="model/best_medsiglip_model.pth", device="cpu"):
        self.device = device
        self.model_path = model_path
        self.model = None
        self.processor = None
        self.bi_rads_classes = ['BI-RADS 1', 'BI-RADS 2', 'BI-RADS 3', 'BI-RADS 4', 'BI-RADS 5']
        self.density_classes = ['DENSITY A', 'DENSITY B', 'DENSITY C', 'DENSITY D']
        
        print("=== MEDSIGLIP INFERENCE SERVICE ===")
        print("Chargement du mod√®le MedSigLIP...")
        self.load_model()
    
    def load_model(self):
        """Charger le mod√®le MedSigLIP entra√Æn√©"""
        try:
            # Charger le mod√®le PyTorch
            if os.path.exists(self.model_path):
                self.model = torch.load(self.model_path, map_location=self.device)
                self.model.eval()
                print(f"‚úÖ Mod√®le charg√©: {self.model_path}")
            else:
                print(f"‚ùå Mod√®le non trouv√©: {self.model_path}")
                return False
            
            # Charger le processeur MedSigLIP
            # Utiliser la variable d'environnement HF_TOKEN ou le token en cache
            hf_token = os.getenv("HF_TOKEN") or os.getenv("HUGGING_FACE_HUB_TOKEN")
            self.processor = AutoProcessor.from_pretrained("google/medsiglip-448", token=hf_token)
            print("‚úÖ Processeur MedSigLIP charg√©")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement: {e}")
            return False
    
    def preprocess_image(self, image_path):
        """Pr√©processer une image pour MedSigLIP"""
        try:
            # Charger l'image
            if isinstance(image_path, str):
                image = Image.open(image_path).convert('RGB')
            else:
                image = image_path
            
            # Redimensionner √† 448x448 (taille MedSigLIP)
            image = image.resize((448, 448))
            
            # Convertir en array numpy
            image_array = np.array(image)
            
            return image_array
            
        except Exception as e:
            print(f"‚ùå Erreur pr√©processing: {e}")
            return None
    
    def predict_single_image(self, image_path):
        """Pr√©dire sur une seule image"""
        try:
            # Pr√©processer l'image
            image_array = self.preprocess_image(image_path)
            if image_array is None:
                return None
            
            # Traiter avec MedSigLIP
            inputs = self.processor(images=image_array, return_tensors="pt")
            
            # D√©placer vers le device
            for key in inputs:
                inputs[key] = inputs[key].to(self.device)
            
            # Pr√©diction
            with torch.no_grad():
                # Extraire les embeddings
                vision_outputs = self.model.model.vision_model(**inputs)
                embeddings = vision_outputs.pooler_output
                
                # Pr√©dictions
                bi_rads_logits = self.model.bi_rads_classifier(embeddings)
                density_logits = self.model.density_classifier(embeddings)
                
                # Probabilit√©s
                bi_rads_probs = torch.softmax(bi_rads_logits, dim=-1)
                density_probs = torch.softmax(density_logits, dim=-1)
                
                # Classes pr√©dites
                bi_rads_pred = torch.argmax(bi_rads_probs, dim=-1).item()
                density_pred = torch.argmax(density_probs, dim=-1).item()
                
                # Confiance
                bi_rads_confidence = bi_rads_probs[0][bi_rads_pred].item()
                density_confidence = density_probs[0][density_pred].item()
            
            # R√©sultats
            results = {
                'bi_rads': {
                    'prediction': self.bi_rads_classes[bi_rads_pred],
                    'confidence': bi_rads_confidence,
                    'probabilities': {
                        class_name: prob.item() 
                        for class_name, prob in zip(self.bi_rads_classes, bi_rads_probs[0])
                    }
                },
                'density': {
                    'prediction': self.density_classes[density_pred],
                    'confidence': density_confidence,
                    'probabilities': {
                        class_name: prob.item() 
                        for class_name, prob in zip(self.density_classes, density_probs[0])
                    }
                }
            }
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erreur pr√©diction: {e}")
            return None
    
    def predict_batch(self, image_paths):
        """Pr√©dire sur un batch d'images"""
        results = []
        
        for i, image_path in enumerate(image_paths):
            print(f"üìä Traitement image {i+1}/{len(image_paths)}: {os.path.basename(image_path)}")
            
            result = self.predict_single_image(image_path)
            if result:
                result['image_path'] = image_path
                results.append(result)
            else:
                results.append({
                    'image_path': image_path,
                    'error': 'Erreur de traitement'
                })
        
        return results
    
    def get_model_info(self):
        """Obtenir les informations du mod√®le"""
        if self.model is None:
            return None
        
        info = {
            'model_type': 'MedSigLIP-448',
            'device': self.device,
            'model_path': self.model_path,
            'bi_rads_classes': self.bi_rads_classes,
            'density_classes': self.density_classes,
            'model_loaded': True
        }
        
        return info

def main():
    """Test du service d'inference"""
    print("=== TEST MEDSIGLIP INFERENCE SERVICE ===")
    
    # Cr√©er le service
    service = MedSigLIPInferenceService()
    
    # V√©rifier que le mod√®le est charg√©
    if service.model is None:
        print("‚ùå Impossible de charger le mod√®le")
        return
    
    # Informations du mod√®le
    info = service.get_model_info()
    print(f"üìä Mod√®le: {info['model_type']}")
    print(f"üìä Device: {info['device']}")
    print(f"üìä Classes BI-RADS: {len(info['bi_rads_classes'])}")
    print(f"üìä Classes Density: {len(info['density_classes'])}")
    
    # Test avec une image (si disponible)
    test_image = "extracted_data/images/sample.jpg"  # Remplacer par une vraie image
    if os.path.exists(test_image):
        print(f"\nüß™ Test avec: {test_image}")
        result = service.predict_single_image(test_image)
        if result:
            print(f"‚úÖ BI-RADS: {result['bi_rads']['prediction']} (confiance: {result['bi_rads']['confidence']:.3f})")
            print(f"‚úÖ Density: {result['density']['prediction']} (confiance: {result['density']['confidence']:.3f})")
        else:
            print("‚ùå Erreur de pr√©diction")
    else:
        print("‚ö†Ô∏è  Aucune image de test trouv√©e")
    
    print("\nüéâ Service d'inference pr√™t !")

if __name__ == "__main__":
    main()
